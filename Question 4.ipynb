{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Maximazing the Dsiplay\npd.set_option('display.max_columns', None) \npd.set_option('display.max_rows', None)\npd.set_option('display.width', None)\n\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nwater_treatment= pd.read_excel('/kaggle/input/water_treatment.xlsx',header=None)\nprint (water_treatment.head())\n\n# PREPROCESSING\n\n# Droping unneccessary columns\nwater_treatment= water_treatment.drop([0],axis=1)\nprint ('Number of columns and rows',water_treatment.shape)\nprint ('Type of each column',water_treatment.dtypes)\n\n\n# Missing Values\n\n# replacing '?' by 0\nwater_treatment=water_treatment.replace('?', 0)\n# Converting all in to float\nwater_treatment = water_treatment.apply(lambda x: x.astype(np.float64), axis=1)\n# Now we can have all the relevant statistics of each column\nprint (water_treatment.describe())\n\n# Replacing '0' of each column with average value\nwater_treatment=water_treatment.replace(0.0,water_treatment.mean())\nprint (water_treatment.head())\n\nfrom sklearn.preprocessing import StandardScaler\nx=water_treatment.ix[:,0:38].values\n\nx = StandardScaler().fit_transform(x)\nfrom sklearn.decomposition import PCA\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(x)\nprincipalDf = pd.DataFrame(data = principalComponents, columns = ['principal component 1', 'principal component 2'])\n\nprint (principalDf.head())\n\nnormalizing_data = principalDf.values #returns a numpy array\nmin_max_scaler = preprocessing.MinMaxScaler()\nnormalized_data = min_max_scaler.fit_transform(normalizing_data)\nprincipalDf_normalized = pd.DataFrame(normalized_data)\n\n# Taking random value of k to start\nclusterNum = 3\nk_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 12)\nk_means.fit(principalDf_normalized)\nlabels = k_means.labels_\nprint(labels)\n\nprincipalDf[\"Cluster\"] = labels\nprint (principalDf.head())\n\nX = principalDf.ix[:,0:2].values\ny = principalDf['Cluster'].values\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)\nfrom sklearn.neighbors import KNeighborsClassifier\nk = 4\n#Train Model and Predict  \nneigh = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nneigh\n\nyhat = neigh.predict(X_test)\nprint (yhat[0:5])\n\nfrom sklearn import metrics\nprint(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, yhat))\n\n# FInding the best k\nKs = 10\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfustionMx = [];\nfor n in range(1,Ks):\n    \n    #Train Model and Predict  \n    neigh = KNeighborsClassifier(n_neighbors = n).fit(X_train,y_train)\n    yhat=neigh.predict(X_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test, yhat)\n\n    \n    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n\nmean_acc\n\n# Visualization \nimport matplotlib.pyplot as plt\nplt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()\n\n# Best K\nprint( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) \n\n# Now for k=1, PCA\nclusterNum = 1\nk_means = KMeans(init = \"k-means++\", n_clusters = clusterNum, n_init = 12)\nk_means.fit(principalDf_normalized)\nlabels = k_means.labels_\nprint(labels)\n\nprincipalDf[\"Cluster\"] = labels\nprint (principalDf.head())\n\n# output file\noutput= principalDf[['Cluster']]\nprint (output.head())\n\n# Saving in text format\noutput.to_csv(r'kmean_PCA.txt', sep='\\t')\n\n\n\n\n\n\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}